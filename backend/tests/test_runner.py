"""
ç»Ÿä¸€æµ‹è¯•è¿è¡Œå™¨

æä¾›ç»Ÿä¸€çš„æµ‹è¯•è¿è¡Œå…¥å£ï¼Œæ”¯æŒé€‰æ‹©æ€§è¿è¡Œï¼š
- å•å…ƒæµ‹è¯•
- é›†æˆæµ‹è¯•  
- æ€§èƒ½æµ‹è¯•
- æ‰€æœ‰æµ‹è¯•
"""

import os
import sys
import argparse
import subprocess
import logging
from typing import List, Dict, Any
from pathlib import Path

logger = logging.getLogger(__name__)


class TestRunner:
    """æµ‹è¯•è¿è¡Œå™¨"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent.parent
        self.tests_root = Path(__file__).parent
        
        # æµ‹è¯•é…ç½®
        self.test_configs = {
            "unit": {
                "description": "å•å…ƒæµ‹è¯• (FastAPI TestClient)",
                "path": "tests/unit/",
                "pattern": "test_*_unit.py",
                "markers": "unit",
                "parallel": False,
                "coverage": True
            },
            "integration": {
                "description": "é›†æˆæµ‹è¯• (çœŸå®HTTPè¯·æ±‚)",
                "path": "tests/integration/",
                "pattern": "test_*_integration.py", 
                "markers": "integration",
                "parallel": False,
                "coverage": False,
                "requires_server": True
            },
            "performance": {
                "description": "æ€§èƒ½æµ‹è¯• (åŸºå‡†æµ‹è¯•)",
                "path": "tests/performance/",
                "pattern": "test_*_performance.py",
                "markers": "performance",
                "parallel": False,
                "coverage": False,
                "timeout": 300
            },
            "legacy": {
                "description": "åŸæœ‰æµ‹è¯•æ–‡ä»¶",
                "path": "tests/",
                "pattern": "test_*.py",
                "exclude_dirs": ["unit", "integration", "performance"],
                "markers": "legacy",
                "parallel": True,
                "coverage": True
            }
        }
    
    def _run_command(self, command: List[str], cwd: str = None, capture_output: bool = True) -> Dict[str, Any]:
        """è¿è¡Œå‘½ä»¤å¹¶è¿”å›ç»“æœ"""
        if cwd is None:
            cwd = str(self.project_root)
        
        logger.info(f"æ‰§è¡Œå‘½ä»¤: {' '.join(command)}")
        logger.info(f"å·¥ä½œç›®å½•: {cwd}")
        
        try:
            # è®¾ç½®ç¯å¢ƒå˜é‡è§£å†³Windowsç¼–ç é—®é¢˜
            env = os.environ.copy()
            env['PYTHONIOENCODING'] = 'utf-8'
            
            if capture_output:
                # æ•è·è¾“å‡ºæ¨¡å¼ï¼ˆç”¨äºæœåŠ¡å™¨æ£€æŸ¥ç­‰ï¼‰
                result = subprocess.run(
                    command,
                    cwd=cwd,
                    capture_output=True,
                    text=True,
                    encoding='utf-8',
                    errors='replace',
                    env=env,
                    timeout=600
                )
                
                return {
                    "success": result.returncode == 0,
                    "returncode": result.returncode,
                    "stdout": result.stdout,
                    "stderr": result.stderr,
                    "command": " ".join(command)
                }
            else:
                # å®æ—¶è¾“å‡ºæ¨¡å¼ï¼ˆç”¨äºæµ‹è¯•æ‰§è¡Œï¼‰
                process = subprocess.Popen(
                    command,
                    cwd=cwd,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.STDOUT,
                    text=True,
                    encoding='utf-8',
                    errors='replace',
                    env=env,
                    bufsize=1,
                    universal_newlines=True
                )
                
                output_lines = []
                while True:
                    output = process.stdout.readline()
                    if output == '' and process.poll() is not None:
                        break
                    if output:
                        print(output.strip())  # å®æ—¶æ‰“å°è¾“å‡º
                        output_lines.append(output.strip())
                
                returncode = process.poll()
                
                return {
                    "success": returncode == 0,
                    "returncode": returncode,
                    "stdout": "\n".join(output_lines),
                    "stderr": "",
                    "command": " ".join(command)
                }
                
        except subprocess.TimeoutExpired:
            logger.error("å‘½ä»¤æ‰§è¡Œè¶…æ—¶")
            return {
                "success": False,
                "returncode": -1,
                "stdout": "",
                "stderr": "å‘½ä»¤æ‰§è¡Œè¶…æ—¶",
                "command": " ".join(command)
            }
        except Exception as e:
            logger.error(f"å‘½ä»¤æ‰§è¡Œå¤±è´¥: {e}")
            return {
                "success": False,
                "returncode": -1,
                "stdout": "",
                "stderr": str(e),
                "command": " ".join(command)
            }
    
    def _check_server_running(self) -> bool:
        """æ£€æŸ¥æœåŠ¡å™¨æ˜¯å¦è¿è¡Œ"""
        try:
            import requests
            # é¦–å…ˆå°è¯•æ£€æŸ¥æ ¹è·¯å¾„æˆ–APIè·¯å¾„
            urls_to_check = [
                "http://127.0.0.1:8000/",
                "http://127.0.0.1:8000/api/health",
                "http://127.0.0.1:8000/docs",
                "http://127.0.0.1:8000/api/"
            ]
            
            for url in urls_to_check:
                try:
                    response = requests.get(url, timeout=3)
                    if response.status_code in [200, 404]:  # 404ä¹Ÿè¯´æ˜æœåŠ¡å™¨åœ¨è¿è¡Œ
                        logger.info(f"âœ… æœåŠ¡å™¨å¥åº·æ£€æŸ¥æˆåŠŸ: {url} -> {response.status_code}")
                        return True
                except:
                    continue
            
            return False
        except Exception as e:
            logger.debug(f"æœåŠ¡å™¨å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    def _display_server_start_instructions(self):
        """æ˜¾ç¤ºæœåŠ¡å™¨å¯åŠ¨è¯´æ˜"""
        logger.info("ğŸš€ é›†æˆæµ‹è¯•éœ€è¦æœåŠ¡å™¨è¿è¡Œ")
        logger.info("ğŸ“ è¯·åœ¨å¦ä¸€ä¸ªç»ˆç«¯ä¸­æ‰§è¡Œä»¥ä¸‹å‘½ä»¤å¯åŠ¨æœåŠ¡å™¨:")
        logger.info("   python start.py dev")
        logger.info("")
        logger.info("ğŸ’¡ å¯åŠ¨æœåŠ¡å™¨åï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼éªŒè¯:")
        logger.info("   - è®¿é—® http://127.0.0.1:8000/docs æŸ¥çœ‹APIæ–‡æ¡£")
        logger.info("   - æˆ–è¿è¡Œ: python run_integration_manual.py")
    

    
    def run_unit_tests(self, verbose: bool = False) -> Dict[str, Any]:
        """è¿è¡Œå•å…ƒæµ‹è¯•"""
        logger.info("ğŸ§ª è¿è¡Œå•å…ƒæµ‹è¯•...")
        
        config = self.test_configs["unit"]
        command = ["python", "-m", "pytest"]
        
        # æ·»åŠ æµ‹è¯•è·¯å¾„
        command.extend([config["path"]])
        
        # æ·»åŠ æ ‡è®°ï¼ˆä¸ä½¿ç”¨-kå‚æ•°ï¼Œå› ä¸ºå®¹æ˜“å‡ºé”™ï¼‰
        command.extend(["-m", config["markers"]])
        
        # å¹¶è¡Œæ‰§è¡Œ
        if config.get("parallel", False):
            command.extend(["-n", "auto"])
        
        # è¦†ç›–ç‡æŠ¥å‘Š
        if config.get("coverage", False):
            command.extend(["--cov=.", "--cov-report=term-missing"])
        
        # è¯¦ç»†è¾“å‡º
        if verbose:
            command.append("-v")
        
        return self._run_command(command, capture_output=False)
    
    def run_integration_tests(self, verbose: bool = False) -> Dict[str, Any]:
        """è¿è¡Œé›†æˆæµ‹è¯•"""
        logger.info("ğŸŒ è¿è¡Œé›†æˆæµ‹è¯•...")
        
        config = self.test_configs["integration"]
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æœåŠ¡å™¨è¿è¡Œ
        if config.get("requires_server", False):
            if not self._check_server_running():
                logger.error("âŒ æœåŠ¡å™¨æœªè¿è¡Œ")
                logger.info("ğŸ’¡ é›†æˆæµ‹è¯•éœ€è¦æœåŠ¡å™¨è¿è¡Œï¼Œè¯·æ‰§è¡Œä»¥ä¸‹æ­¥éª¤:")
                logger.info("   1. åœ¨å¦ä¸€ä¸ªç»ˆç«¯ä¸­å¯åŠ¨æœåŠ¡å™¨:")
                logger.info("      python start.py dev")
                logger.info("   2. ç­‰å¾…æœåŠ¡å™¨å®Œå…¨å¯åŠ¨")
                logger.info("   3. é‡æ–°è¿è¡Œé›†æˆæµ‹è¯•:")
                logger.info("      python tests/test_runner.py integration")
                logger.info("")
                logger.info("ğŸ” æˆ–è€…ä½¿ç”¨æ‰‹åŠ¨é›†æˆæµ‹è¯•è„šæœ¬:")
                logger.info("      python run_integration_manual.py")
                
                return {
                    "success": False,
                    "returncode": -1,
                    "stdout": "",
                    "stderr": "æœåŠ¡å™¨æœªè¿è¡Œï¼Œè¯·æ‰‹åŠ¨å¯åŠ¨æœåŠ¡å™¨",
                    "command": "server check"
                }
            else:
                logger.info("âœ… æœåŠ¡å™¨å·²åœ¨è¿è¡Œï¼Œå¼€å§‹æ‰§è¡Œé›†æˆæµ‹è¯•")
        
        command = ["python", "-m", "pytest"]
        
        # æ·»åŠ æµ‹è¯•è·¯å¾„
        command.extend([config["path"]])
        
        # æ·»åŠ æ ‡è®°ï¼ˆä¸ä½¿ç”¨-kå‚æ•°ï¼Œå› ä¸ºå®¹æ˜“å‡ºé”™ï¼‰
        command.extend(["-m", config["markers"]])
        
        # ä¸å¹¶è¡Œæ‰§è¡Œï¼ˆé›†æˆæµ‹è¯•å¯èƒ½æœ‰ä¾èµ–ï¼‰
        command.extend(["-x"])  # é‡åˆ°å¤±è´¥å°±åœæ­¢
        
        # è¯¦ç»†è¾“å‡º
        if verbose:
            command.append("-v")
        
        return self._run_command(command, capture_output=False)
    
    def run_performance_tests(self, verbose: bool = False) -> Dict[str, Any]:
        """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
        logger.info("âš¡ è¿è¡Œæ€§èƒ½æµ‹è¯•...")
        
        config = self.test_configs["performance"]
        command = ["python", "-m", "pytest"]
        
        # æ·»åŠ æµ‹è¯•è·¯å¾„
        command.extend([config["path"]])
        
        # æ·»åŠ æ ‡è®°ï¼ˆä¸ä½¿ç”¨-kå‚æ•°ï¼Œå› ä¸ºå®¹æ˜“å‡ºé”™ï¼‰
        command.extend(["-m", config["markers"]])
        
        # è¶…æ—¶è®¾ç½®
        if config.get("timeout"):
            command.extend(["--timeout", str(config["timeout"])])
        
        # ä¸å¹¶è¡Œæ‰§è¡Œï¼ˆæ€§èƒ½æµ‹è¯•éœ€è¦ç‹¬å èµ„æºï¼‰
        command.extend(["-x"])  # é‡åˆ°å¤±è´¥å°±åœæ­¢
        
        # è¯¦ç»†è¾“å‡º
        if verbose:
            command.append("-v")
        
        return self._run_command(command, capture_output=False)
    
    def run_legacy_tests(self, verbose: bool = False) -> Dict[str, Any]:
        """è¿è¡ŒåŸæœ‰æµ‹è¯•"""
        logger.info("ğŸ“‚ è¿è¡ŒåŸæœ‰æµ‹è¯•æ–‡ä»¶...")
        
        config = self.test_configs["legacy"]
        command = ["python", "-m", "pytest"]
        
        # æ·»åŠ æµ‹è¯•è·¯å¾„ï¼Œæ’é™¤æ–°ç›®å½•
        exclude_dirs = config.get("exclude_dirs", [])
        test_files = []
        
        for test_file in Path(config["path"]).glob(config["pattern"]):
            # æ£€æŸ¥æ˜¯å¦åœ¨æ’é™¤ç›®å½•ä¸­
            if not any(exclude_dir in str(test_file) for exclude_dir in exclude_dirs):
                test_files.append(str(test_file))
        
        if not test_files:
            logger.info("â„¹ï¸  æ²¡æœ‰æ‰¾åˆ°åŸæœ‰æµ‹è¯•æ–‡ä»¶")
            return {
                "success": True,
                "returncode": 0,
                "stdout": "æ²¡æœ‰åŸæœ‰æµ‹è¯•æ–‡ä»¶",
                "stderr": "",
                "command": "legacy test check"
            }
        
        command.extend(test_files)
        
        # è¦†ç›–ç‡æŠ¥å‘Š
        if config.get("coverage", False):
            command.extend(["--cov=.", "--cov-report=term-missing"])
        
        # è¯¦ç»†è¾“å‡º
        if verbose:
            command.append("-v")
        
        return self._run_command(command, capture_output=False)
    
    def run_all_tests(self, verbose: bool = False) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        logger.info("ğŸš€ è¿è¡Œæ‰€æœ‰æµ‹è¯•...")
        
        results = {}
        overall_success = True
        
        # è¿è¡Œå•å…ƒæµ‹è¯•
        logger.info("\n" + "="*60)
        unit_result = self.run_unit_tests(verbose)
        results["unit"] = unit_result
        if not unit_result["success"]:
            overall_success = False
            logger.error("âŒ å•å…ƒæµ‹è¯•å¤±è´¥")
        else:
            logger.info("âœ… å•å…ƒæµ‹è¯•é€šè¿‡")
        
        # è¿è¡ŒåŸæœ‰æµ‹è¯•
        logger.info("\n" + "="*60)
        legacy_result = self.run_legacy_tests(verbose)
        results["legacy"] = legacy_result
        if not legacy_result["success"]:
            overall_success = False
            logger.error("âŒ åŸæœ‰æµ‹è¯•å¤±è´¥")
        else:
            logger.info("âœ… åŸæœ‰æµ‹è¯•é€šè¿‡")
        
        # è¿è¡Œé›†æˆæµ‹è¯•
        logger.info("\n" + "="*60)
        integration_result = self.run_integration_tests(verbose)
        results["integration"] = integration_result
        if not integration_result["success"]:
            overall_success = False
            logger.error("âŒ é›†æˆæµ‹è¯•å¤±è´¥")
        else:
            logger.info("âœ… é›†æˆæµ‹è¯•é€šè¿‡")
        
        # è¿è¡Œæ€§èƒ½æµ‹è¯•
        logger.info("\n" + "="*60)
        performance_result = self.run_performance_tests(verbose)
        results["performance"] = performance_result
        if not performance_result["success"]:
            overall_success = False
            logger.error("âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥")
        else:
            logger.info("âœ… æ€§èƒ½æµ‹è¯•é€šè¿‡")
        
        # æ±‡æ€»ç»“æœ
        logger.info("\n" + "="*60)
        logger.info("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")
        for test_type, result in results.items():
            status = "âœ…" if result["success"] else "âŒ"
            config = self.test_configs.get(test_type, {})
            description = config.get("description", test_type)
            logger.info(f"   {status} {description}")
        
        return {
            "success": overall_success,
            "returncode": 0 if overall_success else 1,
            "results": results,
            "command": "run_all_tests"
        }
    
    def list_available_tests(self):
        """åˆ—å‡ºå¯ç”¨çš„æµ‹è¯•"""
        logger.info("ğŸ“‹ å¯ç”¨æµ‹è¯•ç±»å‹:")
        
        for test_type, config in self.test_configs.items():
            logger.info(f"\nğŸ”¹ {test_type}:")
            logger.info(f"   æè¿°: {config['description']}")
            logger.info(f"   è·¯å¾„: {config['path']}")
            logger.info(f"   æ¨¡å¼: {config['pattern']}")
            
            if config.get("requires_server"):
                logger.info(f"   ä¾èµ–: éœ€è¦è¿è¡ŒæœåŠ¡å™¨")
            
            if config.get("parallel"):
                logger.info(f"   æ‰§è¡Œ: å¹¶è¡Œ")
            else:
                logger.info(f"   æ‰§è¡Œ: ä¸²è¡Œ")
    
    def generate_test_report(self, results: Dict[str, Any]):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        report_file = self.tests_root / "TEST_REPORT.md"
        
        with open(report_file, "w", encoding="utf-8") as f:
            f.write("# æµ‹è¯•æŠ¥å‘Š\n\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            if "results" in results:
                # æ±‡æ€»æŠ¥å‘Š
                f.write("## æµ‹è¯•æ±‡æ€»\n\n")
                f.write("| æµ‹è¯•ç±»å‹ | çŠ¶æ€ | æè¿° |\n")
                f.write("|----------|------|------|\n")
                
                for test_type, result in results["results"].items():
                    status = "âœ… é€šè¿‡" if result["success"] else "âŒ å¤±è´¥"
                    config = self.test_configs.get(test_type, {})
                    description = config.get("description", test_type)
                    f.write(f"| {test_type} | {status} | {description} |\n")
                
                f.write("\n")
                
                # è¯¦ç»†ç»“æœ
                for test_type, result in results["results"].items():
                    f.write(f"### {test_type} è¯¦ç»†ç»“æœ\n\n")
                    f.write(f"**å‘½ä»¤**: `{result['command']}`\n\n")
                    f.write(f"**è¿”å›ç **: {result['returncode']}\n\n")
                    
                    if result["stdout"]:
                        f.write("**æ ‡å‡†è¾“å‡º**:\n```\n")
                        f.write(result["stdout"])
                        f.write("\n```\n\n")
                    
                    if result["stderr"]:
                        f.write("**é”™è¯¯è¾“å‡º**:\n```\n")
                        f.write(result["stderr"])
                        f.write("\n```\n\n")
            else:
                # å•ä¸ªæµ‹è¯•æŠ¥å‘Š
                f.write("## æµ‹è¯•ç»“æœ\n\n")
                f.write(f"**çŠ¶æ€**: {'âœ… é€šè¿‡' if results['success'] else 'âŒ å¤±è´¥'}\n\n")
                f.write(f"**å‘½ä»¤**: `{results['command']}`\n\n")
                
                if results["stdout"]:
                    f.write("**æ ‡å‡†è¾“å‡º**:\n```\n")
                    f.write(results["stdout"])
                    f.write("\n```\n\n")
                
                if results["stderr"]:
                    f.write("**é”™è¯¯è¾“å‡º**:\n```\n")
                    f.write(results["stderr"])
                    f.write("\n```\n\n")
        
        logger.info(f"ğŸ“„ æµ‹è¯•æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")

def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="ä¿¡ç”¨å¡ç®¡ç†ç³»ç»Ÿæµ‹è¯•è¿è¡Œå™¨")
    parser.add_argument(
        "test_type",
        nargs="?",
        choices=["unit", "integration", "performance", "legacy", "all", "list"],
        default="all",
        help="è¦è¿è¡Œçš„æµ‹è¯•ç±»å‹"
    )
    parser.add_argument(
        "-v", "--verbose",
        action="store_true",
        help="è¯¦ç»†è¾“å‡º"
    )
    parser.add_argument(
        "-r", "--report",
        action="store_true",
        help="ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"
    )
    
    args = parser.parse_args()
    
    # åˆ›å»ºæµ‹è¯•è¿è¡Œå™¨
    runner = TestRunner()
    
    # æ³¨å†Œä¿¡å·å¤„ç†å™¨
    import signal
    def cleanup_handler(signum, frame):
        logger.info("æ¥æ”¶åˆ°é€€å‡ºä¿¡å·ï¼Œæ­£åœ¨é€€å‡º...")
        sys.exit(0)
    
    signal.signal(signal.SIGINT, cleanup_handler)  # Ctrl+C
    if hasattr(signal, 'SIGTERM'):
        signal.signal(signal.SIGTERM, cleanup_handler)  # ç»ˆæ­¢ä¿¡å·
    
    try:
        # åˆ—å‡ºå¯ç”¨æµ‹è¯•
        if args.test_type == "list":
            runner.list_available_tests()
            return
        
        # è¿è¡Œæµ‹è¯•
        result = None
        if args.test_type == "unit":
            result = runner.run_unit_tests(args.verbose)
        elif args.test_type == "integration":
            result = runner.run_integration_tests(args.verbose)
        elif args.test_type == "performance":
            result = runner.run_performance_tests(args.verbose)
        elif args.test_type == "legacy":
            result = runner.run_legacy_tests(args.verbose)
        elif args.test_type == "all":
            result = runner.run_all_tests(args.verbose)
        
        # ç”ŸæˆæŠ¥å‘Š
        if args.report and result:
            from datetime import datetime
            runner.generate_test_report(result)
        
        # é€€å‡ºç 
        if result:
            exit_code = 0 if result["success"] else 1
        else:
            exit_code = 1
            
    except KeyboardInterrupt:
        logger.info("æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        exit_code = 1
    except Exception as e:
        logger.error(f"æµ‹è¯•è¿è¡Œå¤±è´¥: {e}")
        exit_code = 1
        
    sys.exit(exit_code)


if __name__ == "__main__":
    main() 